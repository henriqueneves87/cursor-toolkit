---
name: testing-patterns
description: PadrÃµes para criar testes efetivos com arrange-act-assert, edge cases e testes narrativos. Use quando criar testes unitÃ¡rios, de integraÃ§Ã£o ou end-to-end.
---

# Testing Patterns

## AplicaÃ§Ã£o AutomÃ¡tica

Aplicar quando detectar:
- CriaÃ§Ã£o de arquivos `test_*.py` ou `*_test.py`
- SolicitaÃ§Ã£o de testes para cÃ³digo existente
- Bug fix que precisa de teste de regressÃ£o

## PadrÃ£o AAA (Arrange-Act-Assert)

Todo teste DEVE seguir:

```python
def test_calculo_desconto_aplica_percentual():
    # Arrange â€” preparar dados e dependÃªncias
    preco = 100.0
    desconto = 0.15
    
    # Act â€” executar a funÃ§Ã£o sob teste
    resultado = calcular_preco_final(preco, desconto)
    
    # Assert â€” verificar resultado
    assert resultado == 85.0
```

## Categorias de Teste ObrigatÃ³rias

Para cada funÃ§Ã£o crÃ­tica, criar testes em 3 categorias:

### 1. Happy Path (caso normal)

```python
def test_login_com_credenciais_validas_retorna_token():
    token = login("user@email.com", "senha_correta")
    assert token is not None
    assert len(token) > 0
```

### 2. Error Cases (caso de erro)

```python
def test_login_com_senha_errada_levanta_erro():
    with pytest.raises(AuthenticationError, match="senha invÃ¡lida"):
        login("user@email.com", "senha_errada")
```

### 3. Edge Cases (casos limÃ­trofes)

```python
def test_login_com_email_vazio_levanta_erro():
    with pytest.raises(ValueError):
        login("", "senha")

def test_login_com_none_levanta_type_error():
    with pytest.raises(TypeError):
        login(None, "senha")

def test_calculo_desconto_zero_retorna_preco_original():
    assert calcular_preco_final(100.0, 0.0) == 100.0

def test_calculo_desconto_100_percent_retorna_zero():
    assert calcular_preco_final(100.0, 1.0) == 0.0
```

## NomeaÃ§Ã£o

Formato: `test_[o_que]_[condiÃ§Ã£o]_[resultado_esperado]`

```python
# BOM â€” descritivo
def test_calculate_total_with_empty_cart_returns_zero():
def test_validate_email_with_missing_at_returns_false():
def test_process_batch_with_timeout_raises_error():

# RUIM â€” vago
def test_1():
def test_calculate():
def test_it():
```

## Fixtures e Factories

```python
import pytest

@pytest.fixture
def usuario_valido():
    return {"email": "test@example.com", "nome": "Test User"}

@pytest.fixture
def banco_em_memoria():
    db = criar_banco_memoria()
    yield db
    db.limpar()

def test_criar_usuario(banco_em_memoria, usuario_valido):
    resultado = criar_usuario(banco_em_memoria, usuario_valido)
    assert resultado.id is not None
```

## Testes com Logs Narrativos

Para testes longos, incluir progresso:

```python
def test_pipeline_completo():
    log_ts("Teste 1/3 â€” Preparando dados", "ğŸ”„")
    dados = preparar_dados_teste()
    assert len(dados) > 0
    log_ts("Teste 1/3 concluÃ­do", "âœ…")
    
    log_ts("Teste 2/3 â€” Processando pipeline", "ğŸ”„")
    resultado = processar_pipeline(dados)
    assert resultado.status == "sucesso"
    log_ts("Teste 2/3 concluÃ­do", "âœ…")
    
    log_ts("Teste 3/3 â€” Validando resultados", "ğŸ”„")
    assert validar_resultados(resultado)
    log_ts("Teste 3/3 concluÃ­do", "âœ…")
```

## Invariantes de Testes

- Testes DEVEM ser independentes (sem estado compartilhado mutÃ¡vel)
- Testes DEVEM ser determinÃ­sticos (mesmo resultado toda vez)
- Testes DEVEM ser rÃ¡pidos (evitar I/O desnecessÃ¡rio)
- Testes DEVEM testar comportamento, nÃ£o implementaÃ§Ã£o
- Mock externo, nÃ£o interno (mock API, nÃ£o funÃ§Ã£o interna)

## ProibiÃ§Ãµes

- Testes sem assertions
- Testes que dependem de ordem de execuÃ§Ã£o
- Testes que dependem de dados de produÃ§Ã£o
- Nomes de teste nÃ£o descritivos
- Tests que testam implementaÃ§Ã£o interna em vez de comportamento

## Regra Final

Teste Ã© documentaÃ§Ã£o executÃ¡vel.
Teste sem nome claro Ã© documentaÃ§Ã£o ilegÃ­vel.
**CÃ³digo sem teste Ã© cÃ³digo com prazo de validade.**
